# -*- coding: utf-8 -*-
"""Credit score classification_new

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WfFJ1nIZtLq7rIlVah5yYkw74YofBWjW

Data source: https://www.kaggle.com/datasets/parisrohan/credit-score-classification

*   Logistic Regression, SVM, KNN, PCA, LDA, K-means clustering require scaling
*   Decision Trees, Random Forest, XGBoost, Na√Øve Bayes do not require scaling
*   Validation set is derived from training data, it helps in model hyperparameter tuning. First training is split into training1 and testing. Then the training1 is split into training2 and validation. Training2 is used to fir the data, then prediction is done on validation, if the accuracy is low hyperparameter tuning is done and accuracy is again checked. If the accuracy is good then that model is used on testing data
*

##Imoprting Libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pylab as plt

import warnings
warnings.filterwarnings('ignore')

# pd.set_option('display.max_columns', None)
# pd.set_option('display.max_rows', None)

from google.colab import drive
drive.mount('/content/drive')

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix

from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.tree import plot_tree
from sklearn.decomposition import PCA

"""##Reading Data"""

df_train = pd.read_csv('/content/drive/MyDrive/Credit_Score_Classification/train.csv')
df_test = pd.read_csv('/content/drive/MyDrive/Credit_Score_Classification/test.csv')

df_original = df_train.copy()

print(f'Train data shape: {df_train.shape}, Test data shape: {df_test.shape}\n')
df_train.head(2)

df_test.head(2)

df_train.info()

df_test.info()

"""##EDA"""

df_train.isnull().sum()

df_test.isnull().sum()

df_train['Credit_Score'].value_counts()

# for i in df_train.columns:
#   print(f'unique {i} : {df_train[i].nunique()}')

"""##Data Cleaning"""

def preprocess_credit_data(df):
    df = df.copy()


    target_mapping = {"Poor": 0, "Standard": 1, "Good": 2}
    df["Credit_Score"] = df["Credit_Score"].map(target_mapping)
#-------------------------------------------------------------------------------------------------------------------------------------
    month_mapping = {month: i for i, month in enumerate(
        ['January', 'February', 'March', 'April', 'May', 'June',
         'July', 'August', 'September', 'October', 'November', 'December'], start=1)}
    df['Month'] = df['Month'].map(month_mapping)
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Age'] = df['Age'].astype(str).apply(lambda x: x.replace('_', '')).astype('int64')
    most_freq_age = df.groupby('Customer_ID')['Age'].agg(lambda x: x.mode().iat[0]).reset_index(name='age_mode')
    df = df.merge(most_freq_age, on='Customer_ID', how='left')
    df['Age'] = np.where((df['Age'] < 0) | (df['Age'] > 80), df['age_mode'], df['Age'])
#-------------------------------------------------------------------------------------------------------------------------------------
    most_freq_occ = df.groupby('Customer_ID')['Occupation'].agg(lambda x: x.mode().iat[0]).reset_index(name='occu_mode')
    df = df.merge(most_freq_occ, on='Customer_ID', how='left')
    df['Occupation'] = df['Occupation'].replace('_______', np.nan).fillna(df['occu_mode'])
    df["Occupation"] = df["Occupation"].map(df.groupby("Occupation")["Credit_Score"].mean())
    # df["Occupation_encoded"] = df["Occupation"].map(df.groupby("Occupation")["Credit_Score"].mean())
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Annual_Income'] = df['Annual_Income'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')
    most_freq_ann_inc = df.groupby('Customer_ID')['Annual_Income'].agg(lambda x: x.mode().iat[0]).reset_index(name='annual_income_mode')
    df = df.merge(most_freq_ann_inc, on='Customer_ID', how='left')
    df['Annual_Income'] = np.where(df['Annual_Income'] > 150000, df['annual_income_mode'], df['Annual_Income'])
#-------------------------------------------------------------------------------------------------------------------------------------
    most_freq_salary_value = df.groupby('Customer_ID')['Monthly_Inhand_Salary'].agg(lambda x: x.mode().iat[0]).reset_index(name='salary_mode')
    df = df.merge(most_freq_salary_value, on='Customer_ID', how='left')
    df['Monthly_Inhand_Salary'] = df['Monthly_Inhand_Salary'].astype('float64').fillna(df['salary_mode'])
#-------------------------------------------------------------------------------------------------------------------------------------
    most_freq_bk_acct = df.groupby('Customer_ID')['Num_Bank_Accounts'].agg(lambda x: x.mode().iat[0]).reset_index(name='bk_acct_mode')
    df = df.merge(most_freq_bk_acct, on='Customer_ID', how='left')
    df['Num_Bank_Accounts'] = np.where(df['Num_Bank_Accounts'] <= 0, 0, df['Num_Bank_Accounts'])
    df['Num_Bank_Accounts'] = np.where(df['Num_Bank_Accounts'] > 20, df['bk_acct_mode'], df['Num_Bank_Accounts'])
#-------------------------------------------------------------------------------------------------------------------------------------
    most_freq_cc = df.groupby('Customer_ID')['Num_Credit_Card'].agg(lambda x: x.mode().iat[0]).reset_index(name='cc_mode')
    df = df.merge(most_freq_cc, on='Customer_ID', how='left')
    df['Num_Credit_Card'] = np.where(df['Num_Credit_Card'] > 20, df['cc_mode'], df['Num_Credit_Card'])
#-------------------------------------------------------------------------------------------------------------------------------------
    most_freq_int = df.groupby('Customer_ID')['Interest_Rate'].agg(lambda x: x.mode().iat[0]).reset_index(name='int_mode')
    df = df.merge(most_freq_int, on='Customer_ID', how='left')
    df['Interest_Rate'] = np.where(df['Interest_Rate'] > 50, df['int_mode'], df['Interest_Rate'])
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Num_of_Loan'] = df['Num_of_Loan'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')
    most_freq_ln_value = df.groupby('Customer_ID')['Num_of_Loan'].agg(pd.Series.mode).reset_index(name='num_loans_mode')
    df = df.merge(most_freq_ln_value, on='Customer_ID', how='left')
    df['Num_of_Loan'] = np.where((df['Num_of_Loan'] == -100) | (df['Num_of_Loan'] > 20), df['num_loans_mode'], df['Num_of_Loan'])
#-------------------------------------------------------------------------------------------------------------------------------------
    loan_types = ['Not Specified', 'Credit-Builder Loan', 'Personal Loan', 'Debt Consolidation Loan',
                  'Student Loan', 'Payday Loan', 'Mortgage Loan', 'Auto Loan', 'Home Equity Loan']
    df['Type_of_Loan'] = df['Type_of_Loan'].apply(lambda x: x if x in loan_types else 'Other')
    df["Type_of_Loan"] = df["Type_of_Loan"].map(df.groupby("Type_of_Loan")["Credit_Score"].mean())
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Delay_from_due_date'] = np.where(df['Delay_from_due_date'] <= 0, 0, df['Delay_from_due_date'])
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')
    df['Num_of_Delayed_Payment'] = np.where(df['Num_of_Delayed_Payment'] <= 0, 0, df['Num_of_Delayed_Payment'])
    df['Num_of_Delayed_Payment'] = np.where(df['Num_of_Delayed_Payment'] >= 50, 50, df['Num_of_Delayed_Payment'])
    df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].fillna(0)
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Changed_Credit_Limit'] = pd.to_numeric(df['Changed_Credit_Limit'].apply(lambda x: x.replace('_', '')), errors='coerce').fillna(0)
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Num_Credit_Inquiries'] = np.where(df['Num_Credit_Inquiries'] >= 30, 30, df['Num_Credit_Inquiries'])
    df['Num_Credit_Inquiries'] = df['Num_Credit_Inquiries'].fillna(0)
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Credit_Mix'] = df['Credit_Mix'].replace('_', 'Non Standard')
    credit_mix_mapping = {"Bad": 0, "Standard": 2, "Good": 3, "Non Standard": 1}
    df["Credit_Mix"] = df["Credit_Mix"].map(credit_mix_mapping)
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Outstanding_Debt'] = df['Outstanding_Debt'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')
#-------------------------------------------------------------------------------------------------------------------------------------
    def years_to_months(value):
        try:
            parts = value.split()
            return int(parts[0]) * 12 + int(parts[3])
        except (ValueError, IndexError, AttributeError):
            return np.nan

    df['Credit_History_Age'] = df['Credit_History_Age'].apply(years_to_months)
    df['Credit_History_Age'] = df.groupby('Customer_ID')['Credit_History_Age'].ffill().bfill()
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Payment_of_Min_Amount'] = df['Payment_of_Min_Amount'].replace('NM', 'No')
    df['Payment_of_Min_Amount'] = df['Payment_of_Min_Amount'].map({"No": 0, "Yes": 1})
#-------------------------------------------------------------------------------------------------------------------------------------
    most_freq_emi = df.groupby('Customer_ID')['Total_EMI_per_month'].agg(lambda x: x.mode().iat[0]).reset_index(name='emi_mode')
    df = df.merge(most_freq_emi, on='Customer_ID', how='left')

    df['Total_EMI_per_month'] = np.where(
        df['Total_EMI_per_month'] == df['emi_mode'],
        df['Total_EMI_per_month'],
        df['emi_mode']
    )
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Amount_invested_monthly'] = df['Amount_invested_monthly'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')
    df['Amount_invested_monthly'] = pd.to_numeric(df['Amount_invested_monthly'], errors='coerce')
    df['Amount_invested_monthly'] = df['Amount_invested_monthly'].fillna(0)
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Payment_Behaviour'] = df['Payment_Behaviour'].replace('!@9#%8', 'Other_payments')
    df["Payment_Behaviour"] = df["Payment_Behaviour"].map(df.groupby("Payment_Behaviour")["Credit_Score"].mean())
    # df["Payment_Behaviour_encoded"] = df["Payment_Behaviour"].map(df.groupby("Payment_Behaviour")["Credit_Score"].mean())
#-------------------------------------------------------------------------------------------------------------------------------------
    df['Monthly_Balance'] = df['Monthly_Balance'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')
    df['Monthly_Balance'] = pd.to_numeric(df['Monthly_Balance'], errors='coerce')
    df['Monthly_Balance'] = np.where((df['Monthly_Balance'] <= 0) | pd.isnull(df['Monthly_Balance']),0,df['Monthly_Balance'])
#-------------------------------------------------------------------------------------------------------------------------------------
    cols_remove = ['ID', 'Customer_ID', 'Name', 'SSN',
                   'age_mode', 'occu_mode', 'annual_income_mode', 'salary_mode', 'bk_acct_mode',
                   'cc_mode', 'int_mode', 'num_loans_mode',
                   'emi_mode']
                  #  'Credit_Score'

    df_cleaned = df.drop(columns=cols_remove)

    return df_cleaned

df_processed = preprocess_credit_data(df_train)

df_processed.head()

# corr_matrix = df_processed.corr()
# # corr_matrix

# # Select correlations > 0.5 or < -0.5 (excluding self-correlation)
# filtered_corr = corr_matrix[(corr_matrix > 0.5) | (corr_matrix < -0.5)]

# # Remove diagonal (self-correlation)
# filtered_corr = filtered_corr.where(~(filtered_corr == 1))

# # Display the filtered correlation matrix
# print(filtered_corr)

# # Get pairs of features with high correlation
# high_corr_pairs = (
#     corr_matrix.unstack()
#     .reset_index()
#     .rename(columns={'level_0': 'Feature1', 'level_1': 'Feature2', 0: 'Correlation'})
# )

# # Filter for correlations > 0.5 or < -0.5, excluding duplicates (same feature pair)
# high_corr_pairs = high_corr_pairs[
#     (high_corr_pairs['Correlation'].abs() > 0.5) &
#     (high_corr_pairs['Feature1'] != high_corr_pairs['Feature2'])
# ]

# # Display sorted results
# print(high_corr_pairs.sort_values(by="Correlation", ascending=False))

# Compute correlation matrix
corr_matrix = df_processed.corr()


# Extract correlation values for 'Credit_Score' column
credit_score_corr = corr_matrix["Credit_Score"].sort_values(ascending=False)

# Display the correlation values
print(credit_score_corr)

# # Set figure size
# plt.figure(figsize=(12, 8))

# # Generate heatmap
# sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5)

# # Title
# plt.title("Credit Score Feature Correlation Matrix", fontsize=15)

# # Show plot
# plt.show()

# df_processed_test = preprocess_credit_data(df_test)

"""##ML Algorithms"""

# X = df_processed.drop(columns=['Credit_Score_encoded'])
# y = df_processed['Credit_Score_encoded']

X = df_processed.drop(columns=['Credit_Score'])
y = df_processed['Credit_Score']

X_train_val, X_test, y_train_val, y_test, df_original_train, df_original_test = train_test_split(X, y,df_original, test_size=0.35, random_state=42, stratify=y)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.35, random_state=42, stratify=y_train_val)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_val_scaled = scaler.transform(X_val)

df_results = df_original_test.copy()
df_results["Actual_Credit_Score"] = y_test.values

target_mapping_reverse = {0: "Poor", 1: "Standard", 2: "Good"}
df_results["Actual_Credit_Score"] = df_results["Actual_Credit_Score"].map(target_mapping_reverse)

def evaluate_model(model, X_test, y_test, model_name, dataset):

    # model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"{dataset} Evaluation:\n")
    print(f"{model_name} Accuracy: {accuracy:.4f}\n")
    print(classification_report(y_test, y_pred, target_names=["Poor", "Standard", "Good"]))

    return y_pred, accuracy

def plot_confusion_matrix(y_test, y_pred, model_name):
    conf_matrix = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                xticklabels=["Poor", "Standard", "Good"],
                yticklabels=["Poor", "Standard", "Good"])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title(f"Confusion Matrix - {model_name}")
    plt.show()

"""###Logistic Regression"""

# Logistic Regression

log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500)
log_reg.fit(X_train, y_train)

y_pred_log_val, accuracy_log_val = evaluate_model(log_reg, X_val_scaled, y_val, "Logistic Regression","Validation")
y_pred_log, accuracy_log = evaluate_model(log_reg, X_test_scaled, y_test, "Logistic Regression","Testing")
# plot_confusion_matrix(y_val, y_pred_log_val, "Val - Logistic Regression")
# plot_confusion_matrix(y_test, y_pred_log, "Test - Logistic Regression")

"""###KNN"""

# Normal KNN

knn_model = KNeighborsClassifier(n_neighbors = 2500)
knn_model.fit(X_train_scaled, y_train)
y_pred_knn_val, accuracy_knn_val = evaluate_model(knn_model, X_val_scaled, y_val, "KNN","Validation")

knn_model_tuned = KNeighborsClassifier()

param_grid_knn = {
    'n_neighbors': [5, 50, 750, 1000]
    # 'weights': ['uniform', 'distance'],
    # 'metric': ['euclidean', 'manhattan']
}

grid_search_knn = GridSearchCV(knn_model_tuned, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)
grid_search_knn.fit(X_train_scaled, y_train)

best_knn = grid_search_knn.best_estimator_
print("Best Hyperparameters for KNN:", grid_search_knn.best_params_)

best_knn.fit(X_val_scaled, y_val)
y_pred_knn_val_tuned, accuracy_knn_val_tuned = evaluate_model(best_knn,X_val_scaled,y_val, "KNN","Validation")
y_pred_knn, accuracy_knn = evaluate_model(best_knn,X_test_scaled,y_test, "KNN","Testing")
# plot_confusion_matrix(y_val, y_pred_knn_val, "Val - Logistic Regression")
# plot_confusion_matrix(y_test, y_pred_knn, "Logistic Regression")

# KNN with PCA

# pca = PCA(n_components=2)
# X_train_pca = pca.fit_transform(X_train_scaled)
# X_test_pca = pca.transform(X_test_scaled)
# X_val_pca = pca.transform(X_val_scaled)


# best_knn.fit(X_train_pca, y_train)
# y_pred_knn_val_tuned, accuracy_knn_val_tuned = evaluate_model(best_knn,X_val_scaled,y_val, "KNN","Validation")
# y_pred_knn_pca, accuracy_knn_pca = evaluate_model(best_knn,X_test_scaled,y_test, "KNN","Testing")


# # knn_model_pca = KNeighborsClassifier(n_neighbors=15, metric='euclidean')
# y_pred_knn_pca, accuracy_knn_pca = evaluate_model(knn_model, X_train_pca, X_test_pca, y_train, y_test, "KNN_PCA")
# plot_confusion_matrix(y_test, y_pred_knn_pca, "KNN_PCA")

# pca = PCA(n_components=2)
# X_train_pca = pca.fit_transform(X_train_scaled)
# X_test_pca = pca.transform(X_test_scaled)
# X_val_pca = pca.transform(X_val_scaled)

# best_knn.fit(X_train_pca, y_train)
# y_pred_knn_val_pca, accuracy_knn_val_pca = evaluate_model(best_knn,X_val_scaled,y_val, "KNN","Validation")
# y_pred_knn_pca, accuracy_knn_pca = evaluate_model(best_knn,X_test_scaled,y_test, "KNN","Testing")

# # Create meshgrid for decision boundary visualization
# h = 0.1  # Step size in mesh
# x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1
# y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1
# xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

# # Predict on grid points (make sure to use PCA for grid points as well)
# Z = knn_model.predict(np.c_[xx.ravel(), yy.ravel()])
# Z = Z.reshape(xx.shape)

# # Plot decision boundary
# plt.figure(figsize=(10, 6))
# plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)

# # Scatter plot for training data points
# plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, edgecolor='k', cmap=plt.cm.coolwarm, label="Training data")
# plt.xlabel("Principal Component 1")
# plt.ylabel("Principal Component 2")
# plt.title("KNN Decision Boundary (PCA Reduced Features)")
# plt.legend()
# plt.show()

"""###Decision Tree"""

# Decision Tree

dt = DecisionTreeClassifier(random_state=101, max_depth=5)
dt.fit(X_train, y_train)

y_pred_dt_val, accuracy_dt_val = evaluate_model(dt, X_val, y_val, "Decision Tree", "Validation")

dt_tuned = DecisionTreeClassifier(random_state=101)
param_grid_dt = {'criterion': ['gini', 'entropy'],
                 'max_depth': [3, 6, 8],
                 'min_samples_split': [2000, 5000, 10000],
                 'min_samples_leaf': [1000, 2000, 5000]}
grid_search_dt = GridSearchCV(dt_tuned, param_grid_dt, cv=5, scoring='accuracy', n_jobs=-1)
grid_search_dt.fit(X_train, y_train)

best_dt = grid_search_dt.best_estimator_
print("Best Decision Tree Hyperparameters:", grid_search_dt.best_params_)

y_pred_best_dt_val_tuned, accuracy_best_dt_val_tuned = evaluate_model(best_dt, X_val, y_val, "Best Decision Tree", "Validation")
y_pred_best_dt, accuracy_best_dt = evaluate_model(best_dt, X_test, y_test, "Best Decision Tree", "Testing")
# plot_confusion_matrix(y_test, y_pred_best_dt, "Best Decision Tree")

plt.figure(figsize=(20, 10))
plot_tree(best_dt, feature_names=X.columns, class_names=["Poor", "Standard", "Good"], filled=True, rounded=True, fontsize=8)
plt.title("Best Decision Tree Structure")
plt.show()

"""###XGBoost"""

# XGBoost with Hyperparameter Tuning
xgb = XGBClassifier(eval_metric="mlogloss",random_state=42,n_estimators=10,max_depth=7, learning_rate=0.1)
xgb.fit(X_train, y_train)

y_pred_xgb_val, accuracy_xgb_val = evaluate_model(xgb, X_val, y_val, "XGB", "Validation")
# plot_confusion_matrix(y_test, y_pred_xgb, "XGBoost")

xgb_model_tuned = XGBClassifier(objective='multi:softmax', num_class=3, eval_metric="mlogloss", random_state=42)
param_grid_xgb = {'n_estimators': [5, 8, 10],
                  'max_depth': [3, 5, 7],
                  'learning_rate': [0.01, 0.1, 0.2],
                  'subsample': [0.7, 1.0]}
grid_search_xgb = GridSearchCV(xgb_model_tuned, param_grid_xgb, cv=5, scoring='accuracy', n_jobs=-1)
grid_search_xgb.fit(X_train, y_train)

best_xgb = grid_search_xgb.best_estimator_
print("Best XGBoost Hyperparameters:", grid_search_xgb.best_params_)

best_xgb.fit(X_train, y_train)
y_pred_xgb_val_tuned, accuracy_xgb_val_tuned = evaluate_model(best_xgb, X_val, y_val, "XGBoost_Tuned", "Validation")
y_pred_xgb, accuracy_xgb = evaluate_model(best_xgb, X_test, y_test, "XGBoost_Tuned", "Testing")
# plot_confusion_matrix(y_test, y_pred_xgb, "XGBoost")

"""###Random Forest"""

rf = RandomForestClassifier(n_estimators=10,max_depth=8,random_state=42)
rf.fit(X_train, y_train)

y_pred_rf_val, accuracy_rf_val = evaluate_model(rf, X_val, y_val, "Random Forest", "Validation")

# Random Forest with Hyperparameter Tuning
rf_tuned = RandomForestClassifier(random_state=42)
param_grid_rf = {'n_estimators': [5, 7, 10],
                 'max_depth': [3, 6, 8],
                 'min_samples_split': [5000, 10000, 15000],
                 'min_samples_leaf': [3000, 7000, 10000],
                 'bootstrap': [True, False]}
grid_search_rf = GridSearchCV(rf_tuned, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)
grid_search_rf.fit(X_train, y_train)

best_rf = grid_search_rf.best_estimator_
print("Best Random Forest Hyperparameters:", grid_search_rf.best_params_)

best_rf.fit(X_train,y_train)
y_pred_rf_val_tuned, accuracy_rf_val_tuned = evaluate_model(best_rf, X_val, y_val, "Random Forest","Validation")
y_pred_rf, accuracy_rf = evaluate_model(best_rf, X_test, y_test, "Random Forest","Testing")
# plot_confusion_matrix(y_test, y_pred_rf, "Random Forest")

# Feature Importance for Tree-Based Models
# plt.figure(figsize=(10, 6))
# feature_importances = pd.Series(best_rf.feature_importances_, index=X_train.columns)
# feature_importances.nlargest(10).plot(kind='barh', color='royalblue')
# plt.xlabel("Feature Importance")
# plt.ylabel("Features")
# plt.title("Top 10 Important Features in Random Forest")
# plt.gca().invert_yaxis()
# plt.show()

"""###Naive Bayes"""

# Naive Bayes

nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

y_pred_nb_val, accuracy_nb_val = evaluate_model(nb_model, X_val, y_val, "Naive Bayes", "Validation")

# nb_model = GaussianNB()
# y_pred_nb, accuracy_nb = evaluate_model(nb_model, X_train_scaled, X_test_scaled, y_train, y_test, "Naive Bayes")
# plot_confusion_matrix(y_test, y_pred_nb, "Naive Bayes")

"""###SVM"""

# SVM with Linear Kernel
# svm_model = SVC(kernel='linear', C=1.0, probability=True, random_state=42)
# y_pred_svm, accuracy_svm = evaluate_model(svm_model, X_train_scaled, X_test_scaled, y_train, y_test, "SVM")
# plot_confusion_matrix(y_test, y_pred_svm, "SVM")

# svm_model = SVC(kernel='linear', C=1.0, probability=True, random_state=42)
# svm_model.fit(X_train, y_train)

# y_pred_svm_val, accuracy_svm_val = evaluate_model(svm_model, X_val, y_val, "SVM", "Validation")

"""###Pickle File"""

import joblib

# Assume `model` is your trained classifier
joblib.dump(best_xgb, "credit_score_model.pkl")

import pickle

with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

# import pickle

# Extract encoding mappings
target_encoding_dict = {
    "Credit_Score": {"Poor": 0, "Standard": 1, "Good": 2},
    "Credit_Mix": {"Bad": 0, "Standard": 2, "Good": 3, "Non Standard": 1},
    "Payment_of_Min_Amount": {"No": 0, "Yes": 1},
}

# Compute mean encodings for categorical features
occupation_encoding = df_train.groupby("Occupation")["Credit_Score"].mean().to_dict()
type_of_loan_encoding = df_train.groupby("Type_of_Loan")["Credit_Score"].mean().to_dict()
payment_behaviour_encoding = df_train.groupby("Payment_Behaviour")["Credit_Score"].mean().to_dict()

# Add computed encodings
target_encoding_dict["Occupation"] = occupation_encoding
target_encoding_dict["Type_of_Loan"] = type_of_loan_encoding
target_encoding_dict["Payment_Behaviour"] = payment_behaviour_encoding

# Save the encodings to a .pkl file
with open("target_encodings.pkl", "wb") as f:
    pickle.dump(target_encoding_dict, f)

print("Encodings saved successfully!")

with open("target_encodings.pkl", "rb") as f:
    target_encodings = pickle.load(f)

print(target_encodings)  # Displays the stored encodings

import pickle
import pandas as pd
from sklearn.preprocessing import StandardScaler

# Load the training dataset
df_train = pd.read_csv("your_training_data.csv")  # Replace with actual dataset

# Define numeric columns used for scaling
numeric_cols = ['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts',
                'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date',
                'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries',
                'Outstanding_Debt', 'Credit_History_Age_Months', 'Total_EMI_per_month',
                'Amount_invested_monthly', 'Monthly_Balance', 'Credit_Mix_encoded',
                'Credit_Utilization_Ratio', 'Month_Numeric', 'Occupation_encoded',
                'Payment_Behaviour_encoded']  # Ensure all features are included

# Train scaler
scaler = StandardScaler()
scaler.fit(df_train[numeric_cols])

# Save the scaler and feature names
with open("scaler.pkl", "wb") as f:
    pickle.dump({"scaler": scaler, "features": numeric_cols}, f)

print("Scaler and feature names saved successfully!")

"""##Rough

###Logistic Regression
"""

# log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500)
# log_reg.fit(X_train_scaled, y_train)

# y_pred = log_reg.predict(X_test_scaled)
# y_pred_proba = log_reg.predict_proba(X_test_scaled)

# df_results["Predicted_Credit_Score"] = y_pred
# df_results["Predicted_Credit_Score"] = df_results["Predicted_Credit_Score"].map(target_mapping_reverse)

# accuracy = accuracy_score(y_test, y_pred)
# print(f'Accuracy: {accuracy:.4f}')

# print("\nClassification Report:")
# print(classification_report(y_test, y_pred, target_names=["Poor", "Standard", "Good"]))

# roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class="ovr")
# print(f'\nROC-AUC Score: {roc_auc:.4f}')

# conf_matrix = confusion_matrix(y_test, y_pred)

# plt.figure(figsize=(6,5))
# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=["Poor", "Standard", "Good"], yticklabels=["Poor", "Standard", "Good"])
# plt.xlabel("Predicted Label")
# plt.ylabel("True Label")
# plt.title("Confusion Matrix")
# plt.show()


# from sklearn.metrics import roc_curve, auc
# from itertools import cycle

# # Convert y_test to one-hot encoding
# from sklearn.preprocessing import label_binarize
# y_test_bin = label_binarize(y_test, classes=[0, 1, 2])

# # Colors for each class
# colors = cycle(['blue', 'red', 'green'])
# plt.figure(figsize=(8,6))

# # Compute ROC Curve for each class
# for i, color in zip(range(3), colors):
#     fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])
#     roc_auc = auc(fpr, tpr)
#     plt.plot(fpr, tpr, color=color, lw=2, label=f"Class {i} (AUC = {roc_auc:.2f})")

# # Plot Random Guess Line
# plt.plot([0, 1], [0, 1], 'k--', lw=2)
# plt.xlabel('False Positive Rate')
# plt.ylabel('True Positive Rate')
# plt.title('ROC Curve for Multi-Class Logistic Regression')
# plt.legend(loc="lower right")
# plt.show()

"""###Decision Tree"""

# dt_model = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)
# dt_model.fit(X_train, y_train)

# y_pred_dt = dt_model.predict(X_test)
# y_pred_proba_dt = dt_model.predict_proba(X_test)

# df_results["Predicted_Credit_Score_DT"] = y_pred_dt
# df_results["Predicted_Credit_Score_DT"] = df_results["Predicted_Credit_Score_DT"].map(target_mapping_reverse)

# accuracy_dt = accuracy_score(y_test, y_pred_dt)
# print(f"Decision Tree Accuracy: {accuracy_dt:.4f}")

# print("\nClassification Report:")
# print(classification_report(y_test, y_pred_dt, target_names=["Poor", "Standard", "Good"]))

# conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)
# plt.figure(figsize=(6, 4))
# sns.heatmap(conf_matrix_dt, annot=True, fmt='d', cmap='Blues', xticklabels=["Poor", "Standard", "Good"], yticklabels=["Poor", "Standard", "Good"])
# plt.xlabel("Predicted Label")
# plt.ylabel("Actual Label")
# plt.title("Decision Tree Confusion Matrix")
# plt.show()

# from sklearn.tree import DecisionTreeClassifier
# from sklearn.model_selection import GridSearchCV

# # Define the hyperparameter grid
# param_grid = {
#     'criterion': ['gini', 'entropy'],
#     'max_depth': [3,6,8],
#     'min_samples_split': [2000, 5000, 10000, 20000],
#     'min_samples_leaf': [1000, 2000, 5000, 10000]
# }

# # Initialize the Decision Tree model
# dt = DecisionTreeClassifier(random_state=42)

# # Perform Grid Search with Cross-Validation
# grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)
# grid_search.fit(X_train, y_train)

# # Get the best model
# best_dt_model = grid_search.best_estimator_

# # Print the best hyperparameters
# print("Best Hyperparameters:", grid_search.best_params_)

# # Step 2: Make Predictions using the tuned model
# y_pred_best_dt = best_dt_model.predict(X_test)
# y_pred_proba_best_dt = best_dt_model.predict_proba(X_test)

# # Store predictions in the results DataFrame
# df_results["Predicted_Credit_Score_best_DT"] = y_pred_dt
# df_results["Predicted_Credit_Score_best_DT"] = df_results["Predicted_Credit_Score_best_DT"].map(target_mapping_reverse)

# accuracy_best_dt = accuracy_score(y_test, y_pred_dt)
# accuracy_best_dt



# plt.figure(figsize=(20, 10))

# # Plot the decision tree
# plot_tree(best_dt_model,
#           feature_names=X.columns,  # Feature names
#           class_names=["Poor", "Standard", "Good"],  # Target classes
#           filled=True,
#           rounded=True,
#           fontsize=8)

# # Show the plot
# plt.show()

"""###KNN"""

# # knn_model = KNeighborsClassifier()

# # param_grid_knn = {
# #     'n_neighbors': [10000, 15000, 20000, 25000],
# #     'weights': ['uniform', 'distance'],
# #     'metric': ['euclidean', 'manhattan', 'minkowski']
# # }

# # grid_search_knn = GridSearchCV(knn_model, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)
# # grid_search_knn.fit(X_train_scaled, y_train)

# # # Step 5: Train KNN with best parameters
# # best_knn = grid_search_knn.best_estimator_

# # y_pred_knn = best_knn.predict(X_test_scaled)
# # print("Best Hyperparameters for KNN:", grid_search_knn.best_params_)

# #------------------------------------------------------------------------------------------------------------------------------

# # knn_model = KNeighborsClassifier(n_neighbors=10000, weights='uniform', metric='euclidean') #you can change parameters here

# # knn_model.fit(X_train_scaled, y_train)
# # y_pred_knn = knn_model.predict(X_test_scaled)

# #------------------------------------------------------------------------------------------------------------------------------

# # Apply PCA to reduce dimensions while retaining 95% variance
# pca = PCA(n_components = 2)  # Retains 95% variance
# X_train_pca = pca.fit_transform(X_train_scaled)
# X_test_pca = pca.transform(X_test_scaled)

# # Print the number of components
# print(f"Reduced to {X_train_pca.shape[1]} principal components.")


# # Initialize and train KNN classifier
# knn_model = KNeighborsClassifier(n_neighbors=15000, metric='euclidean')
# knn_model.fit(X_train_pca, y_train)

# # Predict on test data
# y_pred_knn = knn_model.predict(X_test_pca)

# # Store predictions in results dataframe
# df_results["Predicted_Credit_Score_KNN"] = y_pred_knn
# df_results["Predicted_Credit_Score_KNN"] = df_results["Predicted_Credit_Score_KNN"].map(target_mapping_reverse)

# accuracy_knn = accuracy_score(y_test, y_pred_knn)
# print(f"KNN Accuracy: {accuracy_knn:.4f}")

# print("KNN Classification Report:")
# print(classification_report(y_test, y_pred_knn, target_names=target_mapping_reverse.values()))

# # Create meshgrid for decision boundary visualization
# h = 0.1  # Step size in mesh
# x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1
# y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1
# xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

# # Predict on grid points (make sure to use PCA for grid points as well)
# Z = knn_model.predict(np.c_[xx.ravel(), yy.ravel()])
# Z = Z.reshape(xx.shape)

# # Plot decision boundary
# plt.figure(figsize=(10, 6))
# plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)

# # Scatter plot for training data points
# plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, edgecolor='k', cmap=plt.cm.coolwarm, label="Training data")
# plt.xlabel("Principal Component 1")
# plt.ylabel("Principal Component 2")
# plt.title("KNN Decision Boundary (PCA Reduced Features)")
# plt.legend()
# plt.show()

"""###XGBoost"""

# # Initialize XGBoost model
# xgb_model = XGBClassifier(objective='multi:softmax', num_class=3, eval_metric="mlogloss", random_state=42)

# # Define hyperparameter grid
# param_grid_xgb = {
#     'n_estimators': [5, 8, 10],    # Number of trees
#     'max_depth': [3, 5, 7],            # Depth of trees
#     'learning_rate': [0.01, 0.1, 0.2], # Step size at each iteration
#     'subsample': [0.7, 1.0]            # Fraction of samples used per tree
# }

# # Grid Search for best parameters
# grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=5, scoring='accuracy', n_jobs=-1)
# # grid_search_xgb.fit(X_train_scaled, y_train)
# grid_search_xgb.fit(X_train, y_train)

# # Get best model
# best_xgb = grid_search_xgb.best_estimator_

# # Predictions
# # y_pred_xgb = best_xgb.predict(X_test_scaled)
# y_pred_xgb = best_xgb.predict(X_test)

# # Store results
# df_results["Predicted_Credit_Score_XGB"] = y_pred_xgb
# df_results["Predicted_Credit_Score_XGB"] = df_results["Predicted_Credit_Score_XGB"].map(target_mapping_reverse)

# # Print accuracy
# accuracy_xgb = accuracy_score(y_test, y_pred_xgb)
# print(f"XGBoost Accuracy: {accuracy_xgb:.4f}")

# # Print classification report
# print(classification_report(y_test, y_pred_xgb))

# print("Best Hyperparameters:", grid_search_xgb.best_params_)

# import xgboost as xgb
# import matplotlib.pyplot as plt

# # Plot feature importance with actual feature names
# plt.figure(figsize=(10, 6))
# xgb.plot_importance(best_xgb, max_num_features=10, importance_type="gain")  # Adjust importance type if needed
# plt.xticks(rotation=45)  # Rotate feature names for better visibility
# plt.title("Feature Importance in XGBoost")
# plt.show()

"""###Random Forest"""

# rf_model = RandomForestClassifier(random_state=42)

# # Define hyperparameter grid
# param_grid_rf = {
#     'n_estimators': [5, 7, 10],  # Number of trees
#     'max_depth': [3, 6, 8],      # Depth of trees
#     'min_samples_split': [5000, 10000, 15000],  # Min samples required to split a node
#     'min_samples_leaf': [3000, 7000, 10000],    # Min samples per leaf
#     'bootstrap': [True, False]        # Bootstrap sampling
# }


# grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)
# grid_search_rf.fit(X_train, y_train)

# best_rf = grid_search_rf.best_estimator_
# print(f"Best Hyperparameters are: {grid_search_rf.best_params_}")
# y_pred_rf = best_rf.predict(X_test)

# df_results["Predicted_Credit_Score_RF"] = y_pred_rf
# df_results["Predicted_Credit_Score_RF"] = df_results["Predicted_Credit_Score_RF"].map(target_mapping_reverse)


# accuracy_rf = accuracy_score(y_test, y_pred_rf)
# print(f"Random Forest Accuracy: {accuracy_rf:.4f}")

# print(classification_report(y_test, y_pred_rf))

# plt.figure(figsize=(6, 4))
# sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues', xticklabels=target_mapping_reverse.values(), yticklabels=target_mapping_reverse.values())
# plt.xlabel("Predicted")
# plt.ylabel("Actual")
# plt.title("Confusion Matrix - Random Forest")
# plt.show()


# plt.figure(figsize=(10, 6))
# feature_importances = pd.Series(best_rf.feature_importances_, index=X_train.columns)
# feature_importances.nlargest(10).plot(kind='barh', color='royalblue')
# plt.xlabel("Feature Importance")
# plt.ylabel("Features")
# plt.title("Top 10 Important Features in Random Forest")
# plt.gca().invert_yaxis()
# plt.show()

"""###Naive Bayes"""

# from sklearn.naive_bayes import GaussianNB

# # Initialize Naive Bayes model
# nb_model = GaussianNB()

# # Train the model
# nb_model.fit(X_train_scaled, y_train)

# # Make predictions
# y_pred_nb = nb_model.predict(X_test_scaled)

# # Store results
# df_results["Predicted_Credit_Score_NB"] = y_pred_nb
# df_results["Predicted_Credit_Score_NB"] = df_results["Predicted_Credit_Score_NB"].map(target_mapping_reverse)

# # Print accuracy
# accuracy_nb = accuracy_score(y_test, y_pred_nb)
# print(f"Naive Bayes Accuracy: {accuracy_nb:.4f}")

# # Print classification report
# print(classification_report(y_test, y_pred_nb))

# # Confusion Matrix
# plt.figure(figsize=(6, 4))
# sns.heatmap(confusion_matrix(y_test, y_pred_nb), annot=True, fmt="d", cmap="Blues",
#             xticklabels=target_mapping_reverse.values(),
#             yticklabels=target_mapping_reverse.values())
# plt.xlabel("Predicted")
# plt.ylabel("Actual")
# plt.title("Confusion Matrix - Naive Bayes")
# plt.show()

"""###SVM"""

# # from sklearn.svm import SVC
# # import seaborn as sns
# # import matplotlib.pyplot as plt
# # from sklearn.metrics import confusion_matrix

# # Initialize SVM model with linear kernel
# svm_model = SVC(kernel='linear', C=1.0, probability=True, random_state=42)

# # Train the model
# svm_model.fit(X_train_scaled, y_train)

# # Make predictions
# y_pred_svm = svm_model.predict(X_test_scaled)

# # Store results
# df_results["Predicted_Credit_Score_SVM"] = y_pred_svm
# df_results["Predicted_Credit_Score_SVM"] = df_results["Predicted_Credit_Score_SVM"].map(target_mapping_reverse)

# # Print accuracy
# accuracy_svm = accuracy_score(y_test, y_pred_svm)
# print(f"SVM Accuracy: {accuracy_svm:.4f}")

# # Print classification report
# print(classification_report(y_test, y_pred_svm))

# # üìå Confusion Matrix Visualization
# plt.figure(figsize=(6, 4))
# sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt="d", cmap="Blues",
#             xticklabels=target_mapping_reverse.values(),
#             yticklabels=target_mapping_reverse.values())
# plt.xlabel("Predicted")
# plt.ylabel("Actual")
# plt.title("Confusion Matrix - SVM")
# plt.show()

# # üìå Feature Importance (Linear SVM Weights)
# feature_importance = abs(svm_model.coef_).sum(axis=0)
# features = X_train.columns

# # Plot Feature Importance
# plt.figure(figsize=(10, 6))
# sns.barplot(x=feature_importance, y=features, palette="viridis")
# plt.xlabel("Feature Importance (SVM Weights)")
# plt.ylabel("Features")
# plt.title("Feature Importance in SVM")
# plt.show()

"""###Original Data Cleaning"""

# def remove_outliers(df, column, num_stds=1.5):
#   q1 = df[column].quantile(0.25)
#   q3 = df[column].quantile(0.75)
#   iqr = q3 - q1  # Interquartile range
#   lower_bound = q1 - (num_stds * iqr)
#   upper_bound = q3 + (num_stds * iqr)
#   return df[~((df[column] < lower_bound) | (df[column] > upper_bound))]

# df_train_copy['Age'] = df_train_copy['Age'].astype(str).apply(lambda x: x.replace('_', ''))
# df_train_copy['Age'] = df_train_copy['Age'].astype('int64')

# most_freq_age = df_train_copy.groupby('Customer_ID')['Age'].agg(lambda x: x.mode().iat[0]).reset_index(name='age_mode')
# df_train_copy = df_train_copy.merge(most_freq_age, on='Customer_ID', how='left')
# df_train_copy['Age'] = np.where((df_train_copy['Age'] < 0) | (df_train_copy['Age'] > 80), df_train_copy['age_mode'], df_train_copy['Age'])

# most_freq_occ = df_train_copy.groupby('Customer_ID')['Occupation'].agg(lambda x: x.mode().iat[0]).reset_index(name='occu_mode')
# df_train_copy = df_train_copy.merge(most_freq_occ, on='Customer_ID', how='left')

# df_train_copy['Occupation'] = df_train_copy['Occupation'].replace('_______', np.nan)
# df_train_copy['Occupation'] = df_train_copy['Occupation'].fillna(df_train_copy['occu_mode'])

# df_train_copy['Annual_Income'] = df_train_copy['Annual_Income'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')

# most_freq_ann_inc = df_train_copy.groupby('Customer_ID')['Annual_Income'].agg(lambda x: x.mode().iat[0]).reset_index(name='annual_income_mode')
# df_train_copy = df_train_copy.merge(most_freq_ann_inc, on='Customer_ID', how='left')
# df_train_copy['Annual_Income'] = np.where(df_train_copy['Annual_Income'] > 150000, df_train_copy['annual_income_mode'], df_train_copy['Annual_Income'])

# most_freq_salary_value = df_train_copy.groupby('Customer_ID')['Monthly_Inhand_Salary'].agg(lambda x: x.mode().iat[0]).reset_index(name='salary_mode')
# df_train_copy = df_train_copy.merge(most_freq_salary_value, on='Customer_ID', how='left')

# # Ensure both columns are float64
# df_train_copy['Monthly_Inhand_Salary'] = df_train_copy['Monthly_Inhand_Salary'].astype('float64')
# df_train_copy['salary_mode'] = df_train_copy['salary_mode'].astype('float64')

# df_train_copy['Monthly_Inhand_Salary'] = df_train_copy['Monthly_Inhand_Salary'].fillna(df_train_copy['salary_mode'])

# most_freq_bk_acct = df_train_copy.groupby('Customer_ID')['Num_Bank_Accounts'].agg(lambda x: x.mode().iat[0]).reset_index(name='bk_acct_mode')
# df_train_copy = df_train_copy.merge(most_freq_bk_acct, on='Customer_ID', how='left')
# df_train_copy['Num_Bank_Accounts'] = np.where(df_train_copy['Num_Bank_Accounts'] <= 0, 0, df_train_copy['Num_Bank_Accounts'])
# df_train_copy['Num_Bank_Accounts'] = np.where(df_train_copy['Num_Bank_Accounts'] > 20, df_train_copy['bk_acct_mode'], df_train_copy['Num_Bank_Accounts'])

# most_freq_cc = df_train_copy.groupby('Customer_ID')['Num_Credit_Card'].agg(lambda x: x.mode().iat[0]).reset_index(name='cc_mode')
# df_train_copy = df_train_copy.merge(most_freq_cc, on='Customer_ID', how='left')
# df_train_copy['Num_Credit_Card'] = np.where(df_train_copy['Num_Credit_Card'] > 20, df_train_copy['cc_mode'], df_train_copy['Num_Credit_Card'])

# most_freq_int = df_train_copy.groupby('Customer_ID')['Interest_Rate'].agg(lambda x: x.mode().iat[0]).reset_index(name='int_mode')
# df_train_copy = df_train_copy.merge(most_freq_int, on='Customer_ID', how='left')
# df_train_copy['Interest_Rate'] = np.where(df_train_copy['Interest_Rate'] > 50, df_train_copy['int_mode'], df_train_copy['Interest_Rate'])

# df_train_copy['Num_of_Loan'] = df_train_copy['Num_of_Loan'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')

# most_freq_ln_value = df_train_copy.groupby('Customer_ID')['Num_of_Loan'].agg(pd.Series.mode).reset_index(name='num_loans_mode')
# df_train_copy = df_train_copy.merge(most_freq_ln_value, on='Customer_ID', how='left')
# df_train_copy['Num_of_Loan'] = np.where((df_train_copy['Num_of_Loan'] == -100) | (df_train_copy['Num_of_Loan'] > 20),df_train_copy['num_loans_mode'],df_train_copy['Num_of_Loan'])

# loan_types = ['Not Specified','Credit-Builder Loan','Personal Loan','Debt Consolidation Loan','Student Loan','Payday Loan',
#               'Mortgage Loan','Auto Loan','Home Equity Loan']

# def categorize_loan_type(loan):
#   if loan in loan_types:
#     return loan
#   else:
#     return 'Other'

# # Apply the function to the DataFrame
# df_train_copy['Type_of_Loan'] = df_train_copy['Type_of_Loan'].apply(categorize_loan_type)

# df_train_copy['Delay_from_due_date'] = np.where(df_train_copy['Delay_from_due_date'] <= 0, 0, df_train_copy['Delay_from_due_date'])

# df_train_copy['Num_of_Delayed_Payment'] = df_train_copy['Num_of_Delayed_Payment'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')

# df_train_copy['Num_of_Delayed_Payment'] = np.where(df_train_copy['Num_of_Delayed_Payment'] <= 0, 0, df_train_copy['Num_of_Delayed_Payment'])
# df_train_copy['Num_of_Delayed_Payment'] = np.where(df_train_copy['Num_of_Delayed_Payment'] >= 50, 50, df_train_copy['Num_of_Delayed_Payment'])
# df_train_copy['Num_of_Delayed_Payment'] = df_train_copy['Num_of_Delayed_Payment'].fillna(0)

# df_train_copy['Changed_Credit_Limit'] = df_train_copy['Changed_Credit_Limit'].apply(lambda x: x.replace('_', ''))
# df_train_copy['Changed_Credit_Limit'] = pd.to_numeric(df_train_copy['Changed_Credit_Limit'], errors='coerce')
# #
# df_train_copy['Changed_Credit_Limit'] = np.where(df_train_copy['Changed_Credit_Limit'] <= 0, 0, df_train_copy['Changed_Credit_Limit'])
# df_train_copy['Changed_Credit_Limit'] = df_train_copy['Changed_Credit_Limit'].fillna(0)

# df_train_copy['Num_Credit_Inquiries'] = np.where(df_train_copy['Num_Credit_Inquiries'] >= 30, 30, df_train_copy['Num_Credit_Inquiries'])
# df_train_copy['Num_Credit_Inquiries'] = df_train_copy['Num_Credit_Inquiries'].fillna(0)

# df_train_copy['Credit_Mix'] = df_train_copy['Credit_Mix'].replace('_', 'Non Standard')

# df_train_copy['Outstanding_Debt'] = df_train_copy['Outstanding_Debt'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')

# def years_to_months(value):
#   if isinstance(value, str):
#     try:
#       parts = value.split()
#       years = int(parts[0])
#       months = int(parts[3])
#       return years * 12 + months
#     except (ValueError, IndexError):
#       return np.nan
#   else:
#     return value

# df_train_copy['Credit_History_Age_Months'] = df_train_copy['Credit_History_Age'].apply(years_to_months)
# df_train_copy['Credit_History_Age_Months'] = df_train_copy.groupby('Customer_ID')['Credit_History_Age_Months'].ffill().bfill()

# df_train_copy['Payment_of_Min_Amount'] = df_train_copy['Payment_of_Min_Amount'].replace('NM', 'No')

# most_freq_emi = df_train_copy.groupby('Customer_ID')['Total_EMI_per_month'].agg(lambda x: x.mode().iat[0]).reset_index(name='emi_mode')
# df_train_copy = df_train_copy.merge(most_freq_emi, on='Customer_ID', how='left')

# df_train_copy['Total_EMI_per_month'] = np.where(
#     df_train_copy['Total_EMI_per_month'] == df_train_copy['emi_mode'],
#     df_train_copy['Total_EMI_per_month'],
#     df_train_copy['emi_mode']
# )

# df_train_copy['Amount_invested_monthly'] = df_train_copy['Amount_invested_monthly'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')

# df_train_copy['Amount_invested_monthly'] = pd.to_numeric(df_train_copy['Amount_invested_monthly'], errors='coerce')
# df_train_copy['Amount_invested_monthly'] = df_train_copy['Amount_invested_monthly'].fillna(0)

# df_train_copy['Payment_Behaviour'] = df_train_copy['Payment_Behaviour'].replace('!@9#%8', 'Other_payments')

# df_train_copy['Monthly_Balance'] = df_train_copy['Monthly_Balance'].astype(str).apply(lambda x: x.replace('_', '')).astype('float64')

# df_train_copy['Monthly_Balance'] = pd.to_numeric(df_train_copy['Monthly_Balance'], errors='coerce')
# df_train_copy['Monthly_Balance'] = np.where((df_train_copy['Monthly_Balance'] <= 0) | pd.isnull(df_train_copy['Monthly_Balance']),0,df_train_copy['Monthly_Balance'])

# df_sample = df_train_copy.head(20).to_csv('sample_data.csv', index=False)
# df_train_copy['Payment_Behaviour'].unique()

# month_mapping = {
#     'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,
#     'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12
# }

# # if 'Month' in df_train_copy.columns:
# df_train_copy['Month_Numeric'] = df_train_copy['Month'].map(month_mapping)

# target_mapping = {"Poor": 0, "Standard": 1, "Good": 2}
# df_train_copy["Credit_Score_encoded"] = df_train_copy["Credit_Score"].map(target_mapping)

# occupation_target_mean = df_train_copy.groupby("Occupation")["Credit_Score_encoded"].mean()
# df_train_copy["Occupation_encoded"] = df_train_copy["Occupation"].map(occupation_target_mean)

# loan_target_mean = df_train_copy.groupby("Type_of_Loan")["Credit_Score_encoded"].mean()
# df_train_copy["Type_of_Loan_encoded"] = df_train_copy["Type_of_Loan"].map(loan_target_mean)

# credit_mix_mapping = {"Bad": 0, "Standard": 2, "Good": 3,"Non Standard": 1}
# df_train_copy["Credit_Mix_encoded"] = df_train_copy["Credit_Mix"].map(credit_mix_mapping)

# payment_of_min_amount_mapping = {"No": 0, "Yes": 1}
# df_train_copy['Payment_of_Min_Amount_encoded'] = df_train_copy['Payment_of_Min_Amount'].map(payment_of_min_amount_mapping)

# payment_target_mean = df_train_copy.groupby("Payment_Behaviour")["Credit_Score_encoded"].mean()
# df_train_copy["Payment_Behaviour_encoded"] = df_train_copy["Payment_Behaviour"].map(payment_target_mean)

# cols_remove = ['ID','Customer_ID','Month','Name','SSN','Occupation','Type_of_Loan','Credit_Mix','Credit_History_Age','Payment_Behaviour','Credit_Score','age_mode', 'occu_mode', 'annual_income_mode',
#        'salary_mode', 'bk_acct_mode', 'cc_mode', 'int_mode', 'num_loans_mode',
#        'emi_mode','Payment_of_Min_Amount']

# df_train_copy_all_cols = df_train_copy.drop(columns=cols_remove)

# df_train_copy_all_cols_target = df_train_copy_all_cols['Credit_Score_encoded']
# df_train_copy_all_cols = df_train_copy_all_cols.drop(columns=['Credit_Score_encoded'])

# df_train_copy_all_cols.head(1)

# df_train_copy_all_cols.head(10).to_csv('sample2.csv')

# df_processed_cleaned = df_processed.drop(columns=['Credit_Score'])

# scaler = StandardScaler()
# df_processed_scaled = scaler.fit_transform(df_processed)

# df_processed_scaled

# X_train, X_test, y_train, y_test = train_test_split(df_train_copy_all_cols_scaled, df_train_copy_all_cols_target, test_size=0.3, random_state=42, stratify=df_train_copy_all_cols_target)

# # Define models
# models = {
#     "Logistic Regression": LogisticRegression(),
#     "Decision Tree": DecisionTreeClassifier(),
#     "Random Forest": RandomForestClassifier(),
#     "KNN": KNeighborsClassifier(),
#     "Naive Bayes": GaussianNB(),
#     "Gradient Boosting": GradientBoostingClassifier(),
#     "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss")
#     # "SVM": SVC(probability=True),
# }


# # Dictionary to store model accuracies
# model_accuracies = {}

# for name, model in models.items():
#     model.fit(X_train, y_train)
#     y_pred = model.predict(X_test)

#     # Ensure that y_prob contains probability scores for all classes
#     y_prob = model.predict_proba(X_test) if hasattr(model, "predict_proba") else None

#     accuracy = accuracy_score(y_test, y_pred)
#     model_accuracies[name] = accuracy  # Store accuracy


#     print(f"\n==== {name} ====")
#     print("Accuracy:", accuracy_score(y_test, y_pred))
#     print("Classification Report:\n", classification_report(y_test, y_pred))

#     if y_prob is not None:
#         print("ROC AUC Score:", roc_auc_score(y_test, y_prob, multi_class='ovr'))


# # Plot model accuracies
# plt.figure(figsize=(10, 5))
# sns.barplot(x=list(model_accuracies.keys()), y=list(model_accuracies.values()), palette="viridis")
# plt.xlabel("Models")
# plt.ylabel("Accuracy")
# plt.title("Comparison of Model Accuracies")
# plt.xticks(rotation=45)
# plt.ylim(0, 1)  # Accuracy is between 0 and 1
# plt.show()

# # Define hyperparameter grid for Random Forest
# param_grid = {
#     "n_estimators": [50, 100, 200],
#     "max_depth": [None, 10, 20],
#     "min_samples_split": [2, 5, 10]
# }

# grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring="accuracy", n_jobs=-1)
# grid_search.fit(X_train, y_train)

# print("\nBest Hyperparameters:", grid_search.best_params_)
# print("Best Accuracy Score:", grid_search.best_score_)

# # Evaluate best model
# best_model = grid_search.best_estimator_
# y_pred_best = best_model.predict(X_test)
# print("\nFinal Model Performance:")
# print(classification_report(y_test, y_pred_best))

# # Perform cross-validation
# cv_results = {}
# for name, model in models.items():
#     scores = cross_val_score(model, X_scaled, y, cv=5, scoring="accuracy")
#     cv_results[name] = np.mean(scores)

# # Print cross-validation results
# print("\n=== Cross-Validation Accuracy Scores ===")
# for model, score in cv_results.items():
#     print(f"{model}: {score:.4f}")

# q1 = df_train_copy['Credit_Utilization_Ratio'].quantile(0.25)
# q3 = df_train_copy['Credit_Utilization_Ratio'].quantile(0.75)
# iqr = q3 - q1  # Interquartile range
# lower_bound = q1 - (1.5 * iqr)
# upper_bound = q3 + (1.5 * iqr)

# print(lower_bound, upper_bound)

#Remove this customer

# df_train_copy[df_train_copy['Customer_ID']=='CUS_0x9e67']